{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import  MongoClient\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, ExpSineSquared, Matern\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1726020290251
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_mongo():\n",
        "    cs = '''mongodb+srv://pymesadmin:Barcel0na1978$@mongodb-uees-vcore.mongocluster.cosmos.azure.com/gestion_inventarios?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000%60'''\n",
        "    try:\n",
        "        client = MongoClient(cs)\n",
        "        client.admin.command('ping')\n",
        "        print(\"Connected to MongoDB successfully!\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def borrar_archivos_pkl(ruta):\n",
        "    if os.path.exists(ruta) and os.path.isdir(ruta):\n",
        "        for archivo in os.listdir(ruta):\n",
        "            if archivo.endswith(\".pkl\"):\n",
        "                archivo_completo = os.path.join(ruta, archivo)\n",
        "                os.remove(archivo_completo)\n",
        "                print(f\"Archivo eliminado: {archivo_completo}\")\n",
        "    else:\n",
        "        print(\"La ruta no existe o no es un directorio válido.\")\n",
        "\n",
        "def insert_training(database, sku, mae, rmse, rs, start, end, fecha_quiebre, prediccion, incertidumbre):\n",
        "    try:\n",
        "        duration = end - start\n",
        "        collection = database['trainings']\n",
        "        document = {\n",
        "                \"date\": datetime.now(),\n",
        "                \"productSKU\": sku,                \n",
        "                \"mae\": mae,\n",
        "                \"rmse\": rmse, \n",
        "                \"rs\": rs,\n",
        "                \"Duration\":{\n",
        "                \"start\": start,\n",
        "                \"end\": end, \n",
        "                \"duration\": duration.total_seconds()\n",
        "                },\n",
        "                \"fecha_quiebre\": fecha_quiebre,\n",
        "                \"prediccion\": prediccion,\n",
        "                \"incertidumbre\" : incertidumbre ,\n",
        "                \"notes\": \"\"\n",
        "        }            \n",
        "        collection.insert_one(document)\n",
        "        print(f\"Inserted entrenamiento de {sku}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    #finally:\n",
        "    #    client.close()\n",
        "\n",
        "def borrar_entrenamientos_por_sku(database, r):\n",
        "    try:\n",
        "        coleccion = database['colatrainings'] \n",
        "        # Eliminar documentos donde el campo sku sea igual a 'r'\n",
        "        print(f'sku {r}')\n",
        "        resultado = coleccion.delete_many({'sku': r})\n",
        "\n",
        "        print(f'Se eliminaron {resultado.deleted_count} documentos con SKU: {r}')\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar documentos: {e}')\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726020290367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=storageuees;AccountKey=uSahqju2rNAGzygs9nasICLZVZsrLGT+eq+wuBB9rOnq3mhNxsfEdCHeGoVEMVOosVw7KdxEArjY+AStl+onpg==;EndpointSuffix=core.windows.net\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "\n",
        "# Nombre del contenedor y el blob (archivo) donde guardarás el modelo\n",
        "container_name = \"containeruees\"\n",
        "\n",
        "\n",
        "borrar_archivos_pkl('./')\n",
        "client = connect_to_mongo()\n",
        "database = client['gestion_inventarios']\n",
        "\n",
        "collection = database['movimientos']\n",
        "\n",
        "data_productos = collection.distinct(\"Product.productSKU\")\n",
        "\n",
        "colx = database['colatrainings']\n",
        "\n",
        "data_training = colx.distinct(\"sku\")\n",
        "\n",
        "\n",
        "\n",
        "#print(type(data_productos))\n",
        "#print(data_productos[0:2])\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/pymongo/uri_parser.py:313: UserWarning: maxidletimems must be an integer or float\n  return get_validated_options(opts, warn)\n/tmp/ipykernel_14747/899927683.py:4: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n  client = MongoClient(cs)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Connected to MongoDB successfully!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726020293330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for r in data_training:\n",
        "    start = datetime.now()\n",
        "    query = {\"Product.productSKU\": r}\n",
        "    fields = {\"date\":1, \"contador\": 1,\"type\": 1, \"productSKU\":1, \"totalQTY\":1, \"_id\": 0}\n",
        "    resultados = list(collection.find(query, fields).sort(\"date\",1))\n",
        "\n",
        "    data = pd.DataFrame(resultados)\n",
        "\n",
        "    data['dias'] = (data['date'] - data['date'].min()).dt.days\n",
        "\n",
        "    #print(f\"Dato {query}\")    \n",
        "\n",
        "    # Separar las características (X) y el objetivo (y)\n",
        "    X = data[['dias']]  # Usamos los días como entrada\n",
        "    y = data['totalQTY']  # Usamos el stock como salida\n",
        "\n",
        "    # Dividir en entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.01,  random_state=42)\n",
        "\n",
        "    # Combinación de un kernel RBF con un kernel periódico\n",
        "    #kernel = C(1.0, (1e-4, 1e1)) * RBF(10, (1e-2, 1e2)) \n",
        "    kernel = Matern(length_scale=1.0, nu=1.5)\n",
        "\n",
        "    # Crear el modelo de GPR\n",
        "    gpr = GaussianProcessRegressor(kernel = kernel, n_restarts_optimizer=10, alpha=1e-2)\n",
        "\n",
        "    # Entrenar el modelo con los datos de entrenamiento\n",
        "    gpr.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones en el conjunto de prueba\n",
        "    y_pred, sigma = gpr.predict(X_test, return_std=True)\n",
        "\n",
        "    # Calcular las métricas de rendimiento\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    llh = gpr.log_marginal_likelihood()\n",
        "\n",
        "    # Ordenar los datos por el valor de los días\n",
        "    X_test_sorted = X_test.sort_values(by='dias')\n",
        "    y_test_sorted = y_test.loc[X_test_sorted.index]\n",
        "\n",
        "    #print(len(X_test_sorted))\n",
        "    #print(len(y_test_sorted))\n",
        "\n",
        "    # Como y_pred es un array de NumPy, lo ordenamos con los índices del DataFrame convertido a un array\n",
        "    y_pred_sorted = y_pred[X_test_sorted.index.argsort()]\n",
        "\n",
        "    # Supongamos que quieres predecir los próximos 30 días\n",
        "    n_dias_prediccion = 30\n",
        "\n",
        "    nuevos_dias = np.arange(len(data) , len(data) + n_dias_prediccion).reshape(-1,1)\n",
        "\n",
        "    fecha_max = data['date'].max()  #+ pd.Timedelta(days= n_dias_prediccion)\n",
        "\n",
        "    # Asegurarse de que el modelo gp esté entrenado (si no lo está, asegúrate de ejecutar la parte de entrenamiento previamente)\n",
        "    # Hacer predicciones con el modelo entrenado\n",
        "    y_pred_nuevo, sigma_nuevo = gpr.predict(nuevos_dias, return_std=True)\n",
        "\n",
        "    #print(sigma_nuevo)\n",
        "    # Crear un rango de fechas que se extienda a los días predichos\n",
        "    fechas_prediccion = pd.date_range(fecha_max, periods=n_dias_prediccion + 1, freq='D')[1:]\n",
        "    #print(fechas_prediccion)\n",
        "\n",
        "    # Imprimir los resultados de las predicciones\n",
        "    for i, (fecha, pred, incert) in enumerate(zip(fechas_prediccion, y_pred_nuevo, sigma_nuevo)):\n",
        "        if pred > 1:\n",
        "            print(f\"Predicción para el {fecha.strftime('%Y-%m-%d')}: {pred:.2f} con incertidumbre de {incert:.2f}\")\n",
        "        else:\n",
        "            fecha_quiebre = fecha.strftime('%Y-%m-%d')\n",
        "            prediccion = pred\n",
        "            incertidumbre = incert\n",
        "\n",
        "    nombre_modelo = query['Product.productSKU']+'.pkl'\n",
        "    blob_name = \"training_models/\" + nombre_modelo\n",
        "\n",
        "    joblib.dump(gpr, nombre_modelo)\n",
        "\n",
        "    # Guardar el modelo entrenado en Blob Storage\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "\n",
        "    with open(nombre_modelo, \"rb\") as file:\n",
        "        blob_client.upload_blob(file, overwrite=True)\n",
        "\n",
        "    end = datetime.now()\n",
        "\n",
        "    insert_training(database, r, mae, rmse, r2, start, end, fecha_quiebre, prediccion, incert)\n",
        "    print('entrando a borrar')\n",
        "    borrar_entrenamientos_por_sku(database, r)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GaussianProcessRegressor was fitted with feature names\n  warnings.warn(\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GaussianProcessRegressor was fitted with feature names\n  warnings.warn(\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GaussianProcessRegressor was fitted with feature names\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Inserted entrenamiento de QAAAZPWK\nentrando a borrar\nsku QAAAZPWK\nSe eliminaron 1 documentos con SKU: QAAAZPWK\nPredicción para el 2024-07-01: 12.99 con incertidumbre de 0.10\nPredicción para el 2024-07-02: 8.61 con incertidumbre de 0.60\nPredicción para el 2024-07-03: 4.88 con incertidumbre de 0.87\nPredicción para el 2024-07-04: 2.56 con incertidumbre de 0.96\nPredicción para el 2024-07-05: 1.28 con incertidumbre de 0.99\nInserted entrenamiento de QAPQCKZMAAK\nentrando a borrar\nsku QAPQCKZMAAK\nSe eliminaron 1 documentos con SKU: QAPQCKZMAAK\nPredicción para el 2024-07-02: 1.00 con incertidumbre de 0.10\nInserted entrenamiento de QAPWBKAAAAP\nentrando a borrar\nsku QAPWBKAAAAP\nSe eliminaron 1 documentos con SKU: QAPWBKAAAAP\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726020298903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()\n",
        "\n",
        "borrar_archivos_pkl('./')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Archivo eliminado: ./QAAAZPWK.pkl\nArchivo eliminado: ./QAPQCKZMAAK.pkl\nArchivo eliminado: ./QAPWBKAAAAP.pkl\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1726020299146
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "es"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}